{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15d97b16-a983-423c-8281-d626c750b23c",
   "metadata": {},
   "source": [
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/casadoj/efas_hydro.git/HEAD?urlpath=%2Fdoc%2Ftree%2F.%2Fnotebook%2Fglofas_calibration.ipynb)\n",
    "\n",
    "# GloFAS calibration time series\n",
    "\n",
    "This notebook creates a CSV file with the time series of daily discharge needed for the GloFAS calibration. First, it will extract the gauging stations available in the Hydrologial Data Management Service, and then it will download the discharge time series for those stations.\n",
    "\n",
    "As a result, it produces two ZIP files (_stations.zip_, _timeseries.zip_) that contain, respectively, a shapefile of the station metadata and a CSV file with the discharge time series for the selected stations and period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5309e016-0cce-4af4-8b05-900a228b4516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "from efashydro.stations import get_stations, plot_stations\n",
    "from efashydro.timeseries import get_timeseries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17f8c53-00ce-4dfd-83e7-a6fb2686b211",
   "metadata": {},
   "source": [
    "## Configuration \n",
    "\n",
    "In the cell below, to fill in the `USER` and `PASSWORD` below with your credentials, and define the filters for both stations ad time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e059f4-2607-4c35-a1f7-090a0f586e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HDMS API configuration\n",
    "USER = 'xxxxxxxx'\n",
    "PASSWORD = 'yyyyyyyy'\n",
    "\n",
    "# station filters\n",
    "KIND = 'river'\n",
    "COUNTRY_ID = 'PT'\n",
    "PROVIDER_ID = None\n",
    "\n",
    "# time series filters\n",
    "SERVICE = 'nhoperational24hw'\n",
    "VARIABLE = ['D']\n",
    "START = datetime(1980, 1, 1)\n",
    "END = datetime(2024, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da5792a-16b1-42ca-a0a2-bb1d5a13a088",
   "metadata": {},
   "source": [
    "## `get_stations()`\n",
    "\n",
    "The following cell extracts the stations in the database that pass the filters `KIND`, `COUNTRY_ID` and `PROVIDED_ID` defined in the configuration section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b95f1f-81dc-46c6-b964-8c6c97281ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = get_stations(\n",
    "    user=USER, \n",
    "    password=PASSWORD, \n",
    "    kind=KIND,\n",
    "    country_id=COUNTRY_ID,\n",
    "    provider_id=PROVIDER_ID\n",
    ")\n",
    "print(f'Metadata for {len(stations)} stations were extracted')\n",
    "\n",
    "plot_stations(\n",
    "    geometry=stations.geometry,\n",
    "    area=stations.CATCH_SKM,\n",
    "    # extent=[-10, 4.5, 35.5, 44]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c51a57-51a5-4280-8f28-5dfa7f1c2550",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45eee927-4b41-4bae-86fc-d0fef829ca27",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_stations = Path('./stations/')\n",
    "path_stations.mkdir(parents=True, exist_ok=True)\n",
    "filename = 'stations'\n",
    "if COUNTRY_ID is not None:\n",
    "    filename += f'_{COUNTRY_ID}'\n",
    "if PROVIDER_ID is not None:\n",
    "    filename += f'_{PROVIDER_ID}'\n",
    "\n",
    "# as shapefile\n",
    "stations.to_file(path_stations / f'{filename}.shp')\n",
    "# as CSV\n",
    "stations.drop('geometry', axis=1).to_csv(path_stations / f'{filename}.csv')\n",
    "\n",
    "# compress the stations folder\n",
    "zipfile = shutil.make_archive('stations', 'zip', path_stations)\n",
    "print(f'You can now download the compressed file {zipfile} from the file browser.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb51043-ca90-4855-970a-dc7c062be203",
   "metadata": {},
   "source": [
    "The result is a `geopandas.GeoDataFrame` of stations and their metadata. As a `geopandas` object, the stations have associated their geographical location and can be exported to a shapefile to be used in a GIS software."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348c74ff-19cf-42a3-99b2-f9e3db9c0469",
   "metadata": {},
   "source": [
    "## `get_timeseries()`\n",
    "\n",
    "The cell below extracts the time series for the stations selected above. In the configuration section, you must have set up the `SERVICE`, `VARIABLE`, and period of interest (`START`, `END`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e260f2-bbfa-4e76-ac1a-70cb05306de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series = {}\n",
    "for efas_id in tqdm(stations.index, desc='Load timeseries'):\n",
    "    time_series[efas_id] = get_timeseries(\n",
    "        user=USER,\n",
    "        password=PASSWORD,\n",
    "        station_id=efas_id,\n",
    "        service=SERVICE,\n",
    "        variable=VARIABLE, \n",
    "        start=START,\n",
    "        end=END\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b9692e-f06c-470b-b7e4-7b619cb9db5c",
   "metadata": {},
   "source": [
    "The result is a dictionary of `pandas.DataFrames`, where every key is the ID of a station and the value the time series available for that station. These `pandas.DataFrames` could be saved as CSV files, for instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed41f85-abb9-40e2-8f5e-3bc89ae7fb30",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ebd757-f4ed-4aa2-8770-c12e42de7fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_timeseries = Path('./timeseries/')\n",
    "path_timeseries.mkdir(parents=True, exist_ok=True)\n",
    "filename = 'discharge'\n",
    "if COUNTRY_ID is not None:\n",
    "    filename += f'_{COUNTRY_ID}'\n",
    "if PROVIDER_ID is not None:\n",
    "    filename += f'_{PROVIDER_ID}'\n",
    "\n",
    "# concatenate all the time series\n",
    "ts_list = []\n",
    "for efas_id, df in time_series.items():\n",
    "    df.columns = [efas_id]\n",
    "    ts_list.append(df)\n",
    "ts_df = pd.concat(ts_list, axis=1)\n",
    "\n",
    "# make sure the time series cover all the period\n",
    "dates = pd.date_range(START, END, freq='D')\n",
    "if len(ts_df) != len(dates):\n",
    "    ts_df = ts_df.reindex(dates)\n",
    "    ts_df.index.name = 'time'\n",
    "\n",
    "# save as CSV file\n",
    "ts_df.to_csv(path_timeseries / f'{filename}.csv')\n",
    "\n",
    "# compress the time series folder\n",
    "zipfile = shutil.make_archive('timeseries', 'zip', path_timeseries)\n",
    "print(f'You can now download the compressed file {zipfile} from the file browser.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
