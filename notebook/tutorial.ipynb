{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15d97b16-a983-423c-8281-d626c750b23c",
   "metadata": {},
   "source": [
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/casadoj/efas_hydro.git/HEAD?urlpath=%2Fdoc%2Ftree%2F.%2Fnotebook%2Ftutorial.ipynb)\n",
    "<!-- [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.sandbox.google.com/github/casadoj/efas_hydro/blob/main/notebook/tutorial.ipynb) -->\n",
    "\n",
    "# How to extract information from the database using `EFAS-hydro`?\n",
    "\n",
    "In this tutorial we will extract information from the Hydrologial Data Management Service regarding reservoirs in Portugal. To be able to run it, you need to install `efashydro` in your environment, and you need to fill in the `USER` and `PASSWORD` below with your credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4a9ac5-6083-4813-a992-9cee54786586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "from efashydro.stations import get_stations, plot_stations\n",
    "from efashydro.timeseries import get_timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e059f4-2607-4c35-a1f7-090a0f586e27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# HDMS API configuration\n",
    "USER = input(\"Enter your HDMS API username:\")\n",
    "PASSWORD = getpass.getpass(\"Enter your HDMS API password: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da5792a-16b1-42ca-a0a2-bb1d5a13a088",
   "metadata": {},
   "source": [
    "## `get_stations()`\n",
    "\n",
    "To find out the available reservoirs in Portugal we will use the function `get_stations`. Apart from your API credentials, you can introduce several filters to narrow the extraction. In the example below we will only filter by type of station (`kind=reservoir`) and by country (`country_id=PT`)`.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b95f1f-81dc-46c6-b964-8c6c97281ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = get_stations(\n",
    "    user=USER, \n",
    "    password=PASSWORD, \n",
    "    kind='reservoir',\n",
    "    country_id='PT' # country code for Portugal\n",
    ")\n",
    "print(f'Metadata for {len(stations)} stations were extracted')\n",
    "\n",
    "plot_stations(\n",
    "    geometry=stations.geometry,\n",
    "    area=stations.CATCH_SKM,\n",
    "    extent=[-10, 4.5, 35.5, 44] # adjust to your study area\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c51a57-51a5-4280-8f28-5dfa7f1c2550",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45eee927-4b41-4bae-86fc-d0fef829ca27",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_stations = Path('./stations/')\n",
    "path_stations.mkdir(parents=True, exist_ok=True)\n",
    "filename = 'reservoirs_PT'\n",
    "\n",
    "# as shapefile\n",
    "stations.to_file(path_stations / f'{filename}.shp')\n",
    "# as CSV\n",
    "stations.drop('geometry', axis=1).to_csv(path_stations / f'{filename}.csv')\n",
    "\n",
    "# compress the stations folder\n",
    "zipfile = shutil.make_archive('stations', 'zip', path_stations)\n",
    "print(f'You can now download the compressed file {zipfile} from the file browser.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb51043-ca90-4855-970a-dc7c062be203",
   "metadata": {},
   "source": [
    "The result is a `geopandas.GeoDataFrame` of stations and their metadata. As a `geopandas` object, the stations have associated their geographical location and can be exported to a shapefile to be used in a GIS software."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348c74ff-19cf-42a3-99b2-f9e3db9c0469",
   "metadata": {},
   "source": [
    "## `get_timeseries()`\n",
    "\n",
    "Now that we know the Portuguese reservoirs in the database, we can iteratively extract the available time series using the function `get_timeseries`. \n",
    "\n",
    "This function can only extract the time series for a station and a data service at a time, but multiple variables. In the example below, we iterate over the stations and extract the daily historical time series (`service='nhoperationa24hw'`) and all the variables related to reservoirs (`variable=['I', 'O', 'R', 'V']`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e260f2-bbfa-4e76-ac1a-70cb05306de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series = {}\n",
    "for efas_id in tqdm(stations.index, desc='Load timeseries'):\n",
    "    time_series[efas_id] = get_timeseries(\n",
    "        user=USER,\n",
    "        password=PASSWORD,\n",
    "        station_id=efas_id,\n",
    "        service='nhoperational24hw', # historical operational daily values\n",
    "        variable=['I', 'O', 'R', 'V'], # inflow, outflow, reservoir level and storage \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b9692e-f06c-470b-b7e4-7b619cb9db5c",
   "metadata": {},
   "source": [
    "The result is a dictionary of `pandas.DataFrames`, where every key is the ID of a station and the value the time series available for that station. These `pandas.DataFrames` could be saved as CSV files, for instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed41f85-abb9-40e2-8f5e-3bc89ae7fb30",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ebd757-f4ed-4aa2-8770-c12e42de7fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_timeseries = Path('./timeseries/')\n",
    "path_timeseries.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# save as CSV files\n",
    "for efas_id, df in tqdm(time_series.items(), desc='Export timeseries'):\n",
    "    df.to_csv(path_timeseries / f'{efas_id}.csv')\n",
    "\n",
    "# compress the time series folder\n",
    "zipfile = shutil.make_archive('timeseries', 'zip', path_timeseries)\n",
    "print(f'You can now download the compressed file _{zipfile}_ from the file browser.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
